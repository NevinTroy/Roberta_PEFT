{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0",
   "metadata": {
    "id": "a02285e6"
   },
   "source": [
    "# Starter Notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1",
   "metadata": {
    "id": "bdcc5329"
   },
   "source": [
    "Install and import required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "348ceed6-b684-46c3-8a32-9bb640c9a9d7",
    "outputId": "5e1e0309-1c4d-48e0-ebf6-83b97d20164d"
   },
   "outputs": [],
   "source": [
    "!pip install transformers datasets evaluate accelerate peft trl bitsandbytes\n",
    "!pip install nvidia-ml-py3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3",
   "metadata": {
    "id": "cca64f38-d8d2-4313-8295-fbbd43c2a263"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from transformers import (\n",
    "    RobertaForSequenceClassification,\n",
    "    RobertaTokenizer,\n",
    "    TrainingArguments,\n",
    "    Trainer,\n",
    "    DataCollatorWithPadding\n",
    ")\n",
    "from peft import (\n",
    "    LoraConfig,\n",
    "    get_peft_model,\n",
    "    TaskType\n",
    ")\n",
    "from datasets import load_dataset, Dataset\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4",
   "metadata": {
    "id": "59d6e377"
   },
   "source": [
    "## Load Tokenizer and Preprocess Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 585,
     "referenced_widgets": [
      "ecebddc90de947cdbcb14193d991da8b",
      "2eaae4ef1ffa418e895040009b013cf3",
      "a785cb0e075e403daaf18b17016208ec",
      "d951433be70f4a7ebe42f9048161a583",
      "c12d162a29f54d58a6d7f67836a97d48",
      "5f1b35267548498d9573147b8fd194d0",
      "1230c848a80e45cb8bbfbb2a4329a34c",
      "d0219bc98add41c0ba7a4b616cc0b92f",
      "7655d84bfd26486f8c59d83746bdefc6",
      "6735c5cbcae04187991abd6edb263d03",
      "b3c959c6e6544fd0ba4f228772a8f568",
      "44c0c1966a6f4ecbaf8cb2bfc8c94073",
      "d19ed0796aaa41aabb49478bf5cd56d1",
      "1549ffc74a1441468ed16462031edf51",
      "d6636730b4214058b200d7d507ce44f4",
      "8ac86fd1c7704eb1af997268ba31d216",
      "0e37b33d6ae8411eae16b27176cbf768",
      "3409934328154ae9b182e38db9bed672",
      "2f5d6cf3f0e243d99b81e925f809f7e8",
      "42909442da1d448dbb3f78d3710b2212",
      "00aa72461cbc4819bcf48647330b0183",
      "75ca758092aa4fc1b48eab3ff8b19f9b",
      "873a9ad9ed584cf59492de40fc85063f",
      "a99ff6e4ff2d46f0a97ae586ebe47363",
      "c6f8cdd3723841a5a10cfd8541a9a45d",
      "fcb76facf97a4371914eaede55d349a6",
      "86ab74fdbec4413aad346341f5081ffc",
      "8dd4559a2701410098643b3d4b405f47",
      "cc64132be0824661ad3cabe0da727814",
      "86051e7348bc4914978ae5b86bd8cac5",
      "d785a77214604c4780c79b8749392b2d",
      "9e0465bf2bf4450d8fdb071ebb6edc2a",
      "dd8167740a8943b98ff692ed64a2cd96",
      "28d88c66532b4b3c82bc21477ba2ac2c",
      "d7b41e4728c843f2885d970f1cf51a79",
      "c0529898548945f8bc787940214efcb3",
      "f848d26049db4307b08a630106e1bc73",
      "0745e0c040e3418fad75d559c605aee2",
      "f80354f4deec48dfb692404402c61a8f",
      "2c780cb327b74a46b8610e3996d0fc86",
      "caa0723f5bd04a91af507d77da36f7f0",
      "48e6196ed39e4de7afce3aec18eafadf",
      "a8673f3e5ed3478288e409c6e983a3cf",
      "bf9eb2430f6c4116b1cd0141056307cc",
      "c3182ff013474c35ba0b4dba4dcfe761",
      "2bd14191c9624147ad5bb67e138ab177",
      "fda3da09517941939d6151d251bfa4e5",
      "ac7b55bfa75d4d0ea6030336cb09f4c2",
      "277adb16e2c04250a40eeecce9aa9b66",
      "84b081d57e2e43bb96b4171f79813bfd",
      "e021be94a8024bafb717f3c641863f46",
      "727e60f74b9d40fa9109a00a3976b412",
      "bd866465908d4305adf00598c8515d8c",
      "2eeda454928b4f60b8ac681a459c38ce",
      "f54a2c0d1f5d42b3b55e0f461058b0eb",
      "fbb830e9cc8b4a09a568b47357a524c5",
      "cf7daa8c3b9a45cab1dc15bd58380bea",
      "fe3ef1d569db4d50ac0f45995a1c701e",
      "7edb13a49f3f4aab93edb22327b78ab0",
      "4e521c1f8de44539aa3eeef70f028079",
      "cadc0c4cce4b43cbb9fc459cea769371",
      "04476b4ad25a49ccbb65c88ed0eeb4c6",
      "9cf9fa600cd14469aa8117cf205c6488",
      "12ec74711ae9401f9819254a7585cb9c",
      "1bb6bda2c0b74d46a0f0d451ff58b790",
      "c06fce0ebd344c55967e1acbc9408d5e",
      "da2d62b8193d45bd9aeef22e58d52721",
      "a7c0a7a58e744ba2b2ce80607dd8a10c",
      "b1851f34e7fd4daab013bcc86939bc89",
      "84856e18356c4ac99072caa69e23139c",
      "d006281bdcd446a98a7d45d66071c987",
      "1c2a1850fda442b7b820e75099c095d7",
      "2f68aadd006e4b748b324bf1a58269ad",
      "a63b58cb2a7b49eea7b310bd406f419c",
      "527e233094ee4ea3964ecbbc4e581fcf",
      "63520f1dec7840d3a6bc88bb4703ba68",
      "9b2cae503856467da74567db3fe1cd74",
      "50cc12d147b6438283e245a68ad746ed",
      "a6cd69c777564ecc9317581a16a42eff",
      "6fd99e89446d49e990293d4bb25cd622",
      "989646f0cdaf4a69b10ca4bc8dfb7b7f",
      "6e3757b71c1d493b9b6bf3f1db36be18",
      "fb7dde64e85c486dada7ac6172d94d74",
      "00b6f637a70b47d7b70a5bc0eb1332ef",
      "7a4808ec1f81434889f37b942cb63890",
      "64deb7d6e1c848b3b82c5af341ab56ef",
      "783a2e4ca8944c1ead92b0b46ba1a4d9",
      "790709b4ae0b46268290f3c1589e4401",
      "18a3f008e79046a2bebf6e574e859e36",
      "4383775feba84dfcb7e762a8950d0c55",
      "60dde5524a80483da7df6a4efbc0b666",
      "f28de6c880f64b4381d4280a90c50c9f",
      "360667c8920a41e383fb7a751b5361f1",
      "a9e9aab3af0a49cc870cd33e9777be1c",
      "60b7c38a452148b2a056033c4f2cd558",
      "dcc15fd3c0444bc3a4be5075cfcfe67d",
      "be33073652d044929d09577d96655f32",
      "f04707f296ef4d4f953ea3c690225b38",
      "adcfcae301f34baf9702d3afdad011b2",
      "b09f8a24c23e457497c8431c885e7f0a",
      "cc7c9d540416478b9076e64016e89ea2",
      "1d1c5af5038647d8b3d8dbe3d732550f",
      "e67613d724bd4b7887bf94663ffc8d38",
      "ee5d9daac44c49fcb10e8479e264aabd",
      "3365175d67994adb9e245cd563a0c626",
      "e4ee86de40de46c0bce8fa186f4c5582",
      "1e20e767391c47b7ad18d1f2e88b8571",
      "3876e7f889464546b93851615c44e377",
      "0a104a26f571477fb2677d5c2d4d9e05",
      "ab0b4d6843d64c62b9d605b3b30a528d",
      "d675e2eccd5a4c7c94373104385090d6",
      "1ecfa89839a34d44879779e2fc51997e",
      "95dc9d8ad67a4d55a9b3854de9bed308",
      "a38a209dacde4d6eba94aa841885edaf",
      "e533ce409d0a4a7db86fa7a5ce4af9cf",
      "69c89e5aaa0a457b8e7b7f6ed3d366e7",
      "ba31bc52658a43969ae352ee74c4547d",
      "8607f2c21c834dc99b39124f575e7b69",
      "ba00e9789bc44416943901b10aec0aab",
      "76d3294a82ad48deaf341bb399d7abb1",
      "4e7c16e16664449790c28ea220cebe73"
     ]
    },
    "id": "Hw5yWsfOwMwu",
    "outputId": "1497cf6a-604d-48a8-e615-35eb602dcd2f"
   },
   "outputs": [],
   "source": [
    "# Constants\n",
    "BASE_MODEL = \"roberta-base\"\n",
    "DATASET_NAME = \"ag_news\"\n",
    "OUTPUT_DIR = \"roberta_lora_agnews_results\"\n",
    "MAX_LENGTH = 128\n",
    "RANDOM_SEED = 37\n",
    "\n",
    "# Load Dataset\n",
    "dataset = load_dataset(DATASET_NAME, split='train')\n",
    "print(f\"Loaded {len(dataset)} training samples.\")\n",
    "\n",
    "# Load Tokenizer\n",
    "print(f\"Loading tokenizer for base model: {BASE_MODEL}\")\n",
    "tokenizer = RobertaTokenizer.from_pretrained(BASE_MODEL)\n",
    "\n",
    "# Preprocessing Function\n",
    "def preprocess(examples):\n",
    "    \"\"\"Tokenizes the text data with consistent parameters.\"\"\"\n",
    "    return tokenizer(\n",
    "        examples[\"text\"],\n",
    "        truncation=True,\n",
    "        padding=\"max_length\",\n",
    "        max_length=MAX_LENGTH,\n",
    "        return_tensors=None # for batch processing\n",
    "    )\n",
    "\n",
    "# Apply Preprocessing\n",
    "tokenized_dataset = dataset.map(\n",
    "    preprocess,\n",
    "    batched=True,\n",
    "    remove_columns=[\"text\"]\n",
    "    )\n",
    "tokenized_dataset = tokenized_dataset.rename_column(\"label\", \"labels\")\n",
    "\n",
    "# Explicit label mapping ensures consistency between training and inference\n",
    "id2label = {\n",
    "    0: \"World\",\n",
    "    1: \"Sports\",\n",
    "    2: \"Business\",\n",
    "    3: \"Sci/Tech\"\n",
    "}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "print(\"Explicit label mapping for model:\")\n",
    "print(f\"id2label: {id2label}\")\n",
    "print(f\"label2id: {label2id}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9e07f641-bec0-43a6-8c26-510d7642916a",
    "outputId": "8a890cfb-3f49-4447-accb-fae7c84125ef"
   },
   "outputs": [],
   "source": [
    "# Extract the number of classess and their names\n",
    "num_labels = dataset.features['label'].num_classes\n",
    "class_names = dataset.features[\"label\"].names\n",
    "print(f\"number of labels: {num_labels}\")\n",
    "print(f\"the labels: {class_names}\")\n",
    "\n",
    "# Create an id2label mapping\n",
    "# We will need this for our classifier.\n",
    "id2label = {i: label for i, label in enumerate(class_names)}\n",
    "label2id = {label: i for i, label in enumerate(class_names)}\n",
    "\n",
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7",
   "metadata": {
    "id": "c9e24afd"
   },
   "source": [
    "## Load Pre-trained Model\n",
    "Set up config for pretrained model and download it from hugging face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 926,
     "referenced_widgets": [
      "57bbdd53cec545e49a784d8152b2105c",
      "9cc2939b12ee47578a2cffeb3c8a82cc",
      "e32413cabde34e18ab9b7c081bd433fa",
      "af0dc8a1d3d14acf8626fc3d03e961bb",
      "019f6285a9ee4aebb34058fa1b6c1685",
      "04957f4d03d94c44a0b33d4fad18e776",
      "0261ccc791d54881b32b155ac914e250",
      "b09af2ab420b426bb81c73be130f39c7",
      "73e0b45b238146359c6f301a911cf042",
      "b2341e64220c4083b3359abfb2115044",
      "8e6ff0a7d25343878052fdae34421cf8"
     ]
    },
    "id": "262a8416-a59c-4ea1-95d9-0b1f81d6094c",
    "outputId": "39e2673a-3256-49ab-ffbb-0040ac6076cb"
   },
   "outputs": [],
   "source": [
    "model = RobertaForSequenceClassification.from_pretrained(\n",
    "    BASE_MODEL,\n",
    "    num_labels=4,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id)\n",
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9",
   "metadata": {
    "id": "f265839d-a088-4693-8474-862641de11ed"
   },
   "source": [
    "## Anything from here on can be modified"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "e7413430-be57-482b-856e-36bd4ba799df",
    "outputId": "a67a06fd-0f37-4017-859e-65d405eac27b"
   },
   "outputs": [],
   "source": [
    "# Split Dataset\n",
    "split_datasets = tokenized_dataset.train_test_split(\n",
    "    test_size=0.1,\n",
    "    seed=37,\n",
    "    stratify_by_column=\"labels\"\n",
    "    )\n",
    "train_dataset = split_datasets[\"train\"]\n",
    "eval_dataset = split_datasets[\"test\"]\n",
    "print(f\"Training set size: {len(train_dataset)}\")\n",
    "print(f\"Evaluation set size: {len(eval_dataset)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11",
   "metadata": {
    "id": "Yn6ES1Kty14g"
   },
   "outputs": [],
   "source": [
    "# Freeze all parameters of the base model\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12",
   "metadata": {
    "id": "652452e3"
   },
   "source": [
    "## Setup LoRA Config\n",
    "Setup PEFT config and get peft model for finetuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13",
   "metadata": {
    "id": "bd0ca0ea-86b8-47f7-8cbf-83da25685876"
   },
   "outputs": [],
   "source": [
    "# Running PEFT Config on LoRA configuration\n",
    "peft_config = LoraConfig(\n",
    "    r=8, # Rank of the update matrices, higher it is, better the capacity\n",
    "    lora_alpha=16, # LoRA scaling factor = 2*Rank\n",
    "    lora_dropout=0.2, # Dropout probability for LoRA layers\n",
    "    bias = 'lora_only',\n",
    "    target_modules = [\"query\", \"value\"],\n",
    "    task_type=\"SEQ_CLS\",\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "6ec2739d-76b6-4fde-91c2-0fc49e1884b0",
    "outputId": "02118e8b-43a9-4182-832f-bece410f40ae"
   },
   "outputs": [],
   "source": [
    "print(\"Applying LoRA configuration to the base model-\")\n",
    "peft_model = get_peft_model(model, peft_config)\n",
    "peft_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "da45f85c-b016-4c49-8808-6eafa7cb5d1b",
    "outputId": "98ee1f74-a06c-4692-9146-2df52ff2329d"
   },
   "outputs": [],
   "source": [
    "print('PEFT Model')\n",
    "peft_model.print_trainable_parameters()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ozWpS3t50gkI",
    "outputId": "87f747c0-ada2-400a-b1d2-fc325e80bc0e"
   },
   "outputs": [],
   "source": [
    "# Calculate trainable parameters manually for verification\n",
    "trainable_params = sum(p.numel() for p in peft_model.parameters() if p.requires_grad)\n",
    "total_params = sum(p.numel() for p in peft_model.parameters())\n",
    "print(f\"Trainable parameters: {trainable_params:,}\")\n",
    "print(f\"Total parameters: {total_params:,}\")\n",
    "print(f\"Percentage of trainable parameters: {100 * trainable_params / total_params:.4f}%\")\n",
    "\n",
    "# Verify we're under 1M trainable parameters\n",
    "assert trainable_params < 1_000_000, \"Trainable parameters exceed 1 million!\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "a769f54e-05ad-4e3c-aae8-d00d1d9dfb2f",
    "outputId": "2dbac79f-9643-4a4d-98ce-0562027b6b6e"
   },
   "outputs": [],
   "source": [
    "print(\"Trainable parameters:\")\n",
    "for name, param in peft_model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "         print(name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18",
   "metadata": {
    "id": "12284b58"
   },
   "source": [
    "## Training Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19",
   "metadata": {
    "id": "0ee64c43-fe38-479a-b3c5-7d939a3db4c1"
   },
   "outputs": [],
   "source": [
    "data_collator = DataCollatorWithPadding(tokenizer=tokenizer, return_tensors=\"pt\")\n",
    "\n",
    "# To track evaluation accuracy during training\n",
    "def compute_metrics(eval_pred):\n",
    "    logits, labels = eval_pred\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "    return {\"accuracy\": accuracy_score(labels, predictions)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "VeiqgUd52Vag",
    "outputId": "0d05821b-84b0-4260-df82-6105043d0444"
   },
   "outputs": [],
   "source": [
    "# Setup Training args\n",
    "output_dir = \"results\"\n",
    "training_args = TrainingArguments(\n",
    "    output_dir=\"roberta-lora-agnews-results\",\n",
    "    # learning_rate=5e-4,\n",
    "    learning_rate=1e-4,\n",
    "    per_device_train_batch_size=32,\n",
    "    per_device_eval_batch_size=64,\n",
    "    num_train_epochs=6,\n",
    "    # max_steps=1200 # consider either max steps or desired epochs\n",
    "    eval_strategy='steps', # Evaluate during training\n",
    "    eval_steps=200,\n",
    "    save_strategy=\"steps\", # Save checkpoints during training\n",
    "    save_steps=200, # Save checkpoints at the same frequency as evaluation\n",
    "    load_best_model_at_end=True, # Load the best model found during training\n",
    "    metric_for_best_model=\"accuracy\", # Use accuracy to determine the best model\n",
    "    greater_is_better=True,\n",
    "    weight_decay=0.01,\n",
    "    optim=\"adamw_torch\",\n",
    "    max_grad_norm=1.0,\n",
    "    lr_scheduler_type=\"linear\",\n",
    "    report_to=None, # Disable default reporting integrations like wandb/tensorboard unless configured\n",
    "    fp16=torch.cuda.is_available(), # Use mixed precision if GPU is available\n",
    "    gradient_accumulation_steps=4, # Accumulate gradients to simulate larger batch size if needed\n",
    "    warmup_ratio=0.1, # Add a learning rate warmup phase\n",
    "    seed=37,\n",
    "    logging_steps=50,\n",
    "    gradient_checkpointing=True, # Enable if memory is constrained, might slow down training\n",
    ")\n",
    "\n",
    "print(\"\\nTraining Arguments:\")\n",
    "print(training_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21",
   "metadata": {
    "id": "yO-pTEPg6Cny"
   },
   "outputs": [],
   "source": [
    "# initialize trainer\n",
    "def get_trainer(model):\n",
    "      return  Trainer(\n",
    "          model=peft_model,\n",
    "          args=training_args,\n",
    "          compute_metrics=compute_metrics,\n",
    "          train_dataset=train_dataset,\n",
    "          eval_dataset=eval_dataset,\n",
    "          data_collator=data_collator,\n",
    "          tokenizer=tokenizer,\n",
    "      )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22",
   "metadata": {
    "id": "9b848278"
   },
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "98d9d57d-b57f-4acc-80fb-fc5443e75515",
    "outputId": "e4376147-9cd5-4f03-f8eb-fe881125eb08"
   },
   "outputs": [],
   "source": [
    "peft_lora_finetuning_trainer = get_trainer(peft_model)\n",
    "\n",
    "result = peft_lora_finetuning_trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LinUBayC8hKs",
    "outputId": "75c9b595-5f3a-4f27-e204-89438d2466f3"
   },
   "outputs": [],
   "source": [
    "# Save Final Model\n",
    "print(\"Training finished. Saving model...\")\n",
    "peft_lora_finetuning_trainer.save_model(os.path.join(OUTPUT_DIR, \"final_model\"))\n",
    "tokenizer.save_pretrained(os.path.join(OUTPUT_DIR, \"final_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25",
   "metadata": {
    "id": "5183be7e-514f-4e64-a6f4-314a827e6be5"
   },
   "source": [
    "## Evaluate Finetuned Model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26",
   "metadata": {
    "id": "038198cf-0953-47e7-bd47-b073d05f8378"
   },
   "source": [
    "### Performing Inference on Custom Input\n",
    "Uncomment following functions for running inference on custom inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 75
    },
    "id": "QHTH5BNQ8qJw",
    "outputId": "dc4faa21-f9dd-4126-fe47-6486640a9d95"
   },
   "outputs": [],
   "source": [
    "# Evaluate Model\n",
    "eval_metrics = peft_lora_finetuning_trainer.evaluate()\n",
    "print(f\"Final evaluation metrics: {eval_metrics}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28",
   "metadata": {
    "id": "f88ad420-3f46-4eff-9d71-0ce388163062"
   },
   "outputs": [],
   "source": [
    "def classify(model, tokenizer, text):\n",
    "    \"\"\"Run inference on a single text example.\"\"\"\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    inputs = tokenizer(text, truncation=True, padding=True, return_tensors=\"pt\")\n",
    "    inputs = {k: v.to(device) for k, v in inputs.items()}\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "        output = model(**inputs)\n",
    "    prediction = output.logits.argmax(dim=-1).item()\n",
    "    print(f'Class: {prediction}, Label: {id2label[prediction]}, Text: {text}')\n",
    "    return id2label[prediction]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29",
   "metadata": {
    "id": "68a3e276-bf8c-4403-8a48-5ef19f2beccf"
   },
   "source": [
    "### Run Inference on eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "809635a6-a2c7-4d09-8d60-ababd1815003",
    "outputId": "44b30e56-7592-4a57-bce3-f9d187ba6b83"
   },
   "outputs": [],
   "source": [
    "# Run Inference on Test Examples\n",
    "test_examples = [\n",
    "    \"Wall Street rallies as tech stocks surge to new heights\",\n",
    "    \"Manchester United wins dramatic match against Liverpool\",\n",
    "    \"New study reveals breakthrough in cancer treatment\",\n",
    "    \"Tech company announces innovative AI product\",\n",
    "    \"NVIDIA owns AI\"\n",
    "]\n",
    "\n",
    "print(\"\\nRunning inference on test examples:\")\n",
    "for text in test_examples:\n",
    "    result = classify(peft_model, tokenizer, text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31",
   "metadata": {
    "id": "ebbc20a2-a1c0-4cb7-b842-f52e4de61ed5"
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "import evaluate\n",
    "from tqdm import tqdm\n",
    "\n",
    "def evaluate_model(inference_model, dataset, labelled=True, batch_size=32, data_collator=None):\n",
    "    \"\"\"\n",
    "    Evaluate a PEFT model on a dataset.\n",
    "\n",
    "    Args:\n",
    "        inference_model: The model to evaluate.\n",
    "        dataset: The dataset (Hugging Face Dataset) to run inference on.\n",
    "        labelled (bool): If True, the dataset includes labels and metrics will be computed.\n",
    "                         If False, only predictions will be returned.\n",
    "        batch_size (int): Batch size for inference.\n",
    "        data_collator: Function to collate batches. If None, the default collate_fn is used.\n",
    "\n",
    "    Returns:\n",
    "        If labelled is True, returns a tuple (metrics, predictions)\n",
    "        If labelled is False, returns the predictions.\n",
    "    \"\"\"\n",
    "    # Create the DataLoader\n",
    "    eval_dataloader = DataLoader(dataset, batch_size=batch_size, collate_fn=data_collator)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    inference_model.to(device)\n",
    "    inference_model.eval()\n",
    "\n",
    "    all_predictions = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "      # Loop over the DataLoader\n",
    "      for batch in tqdm(eval_dataloader, desc=\"Evaluating\"):\n",
    "          # Move each tensor in the batch to the device\n",
    "          batch = {k: v.to(device) for k, v in batch.items()}\n",
    "\n",
    "          # Forward pass\n",
    "          outputs = inference_model(**batch)\n",
    "          predictions = outputs.logits.argmax(dim=-1)\n",
    "\n",
    "          all_predictions.extend(predictions.cpu().numpy())\n",
    "          if labelled and \"labels\" in batch:\n",
    "              all_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "              # Calculate accuracy\n",
    "              metric = evaluate.load('accuracy')\n",
    "\n",
    "    # Compute metrics if dataset is labelled\n",
    "    if labelled and all_labels:\n",
    "        accuracy = accuracy_score(all_labels, all_predictions)\n",
    "\n",
    "        metrics = {\n",
    "            \"accuracy\": accuracy,\n",
    "        }\n",
    "\n",
    "        print(f\"Evaluation metrics: {metrics}\")\n",
    "        return metrics, all_predictions\n",
    "\n",
    "    return all_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 513,
     "referenced_widgets": [
      "e5539eed7d174bd5a4d949584be7b8f8",
      "406704287a644f8d8bed0b068c0cdc28",
      "12c67b4795d44ed39fd9fc4e7b910237",
      "0bf560950857434498447d5659a24764",
      "f87a346857634471bd61e9905013d03e",
      "094fb214f3454a349456162cf5785e35",
      "1214e2b9f56d47c1802e56ab1f9c4234",
      "aa2e88b3e8684efba4a85aa6a879e13c",
      "19bafbaa6a214c4a814ca28fb54a9392",
      "c3fdd2fe36be47218c02e12d3fa1e071",
      "5c6c14d0cd1543e1953fa0af670b1154"
     ]
    },
    "id": "IOBHX0NuiBhz",
    "outputId": "79789b71-c1d4-4d48-e164-aa67cc58ba28"
   },
   "outputs": [],
   "source": [
    "# Process Test Data for Submission\n",
    "try:\n",
    "    print(\"\\nLoading test data for Kaggle submission...\")\n",
    "    test_data_path = \"test_unlabelled.pkl\"\n",
    "\n",
    "    # Load the pickle file\n",
    "    test_df = pd.read_pickle(test_data_path)\n",
    "    print(f\"Loaded data type: {type(test_df)}\")\n",
    "\n",
    "    # If it's already a Dataset object, convert to DataFrame first\n",
    "    if hasattr(test_df, 'to_pandas'):\n",
    "        print(\"Converting Dataset to DataFrame...\")\n",
    "        test_df = test_df.to_pandas()\n",
    "    elif not isinstance(test_df, pd.DataFrame):\n",
    "        print(f\"Unexpected data type: {type(test_df)}. Converting to DataFrame...\")\n",
    "        if hasattr(test_df, 'features'):\n",
    "            # It's a Dataset-like object\n",
    "            test_df = pd.DataFrame({col: test_df[col] for col in test_df.column_names})\n",
    "        else:\n",
    "            # Try to convert directly\n",
    "            test_df = pd.DataFrame(test_df)\n",
    "\n",
    "    print(f\"Successfully loaded test data with shape: {test_df.shape}\")\n",
    "\n",
    "    # Ensure 'ID' column exists in the DataFrame\n",
    "    if \"ID\" not in test_df.columns:\n",
    "        test_df[\"ID\"] = range(len(test_df))\n",
    "\n",
    "    # Convert to Hugging Face Dataset\n",
    "    test_dataset = Dataset.from_pandas(test_df)\n",
    "\n",
    "    # Apply the same preprocessing as training data\n",
    "    test_dataset = test_dataset.map(preprocess, batched=True, remove_columns=[\"text\"])\n",
    "\n",
    "    # Run inference\n",
    "    print(\"Running inference on test data...\")\n",
    "    predictions = peft_lora_finetuning_trainer.predict(test_dataset)\n",
    "    pred_labels = np.argmax(predictions.predictions, axis=-1)\n",
    "\n",
    "    # Create submission DataFrame with EXACT column names required\n",
    "    submission_df = pd.DataFrame({\n",
    "        'ID': test_df[\"ID\"],  # Use the original IDs from the test set!\n",
    "        'Label': pred_labels  # Numeric labels (0, 1, 2, 3)\n",
    "    })\n",
    "\n",
    "    # Save to CSV without index\n",
    "    submission_path = os.path.join(OUTPUT_DIR, \"kaggle_submission.csv\")\n",
    "    submission_df.to_csv(submission_path, index=False)\n",
    "    print(f\"Kaggle submission file saved to {submission_path}\")\n",
    "    print(submission_df.head())\n",
    "\n",
    "except Exception as e:\n",
    "    print(f\"Error processing test data: {e}\")\n",
    "    import traceback\n",
    "    traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "U_TtIZHtia8A",
    "outputId": "fff8325b-fd78-4634-cd21-bd540965a527"
   },
   "outputs": [],
   "source": [
    "print(f\"Base Model: {BASE_MODEL}\")\n",
    "print(f\"LoRA Rank (r): {peft_config.r}\")\n",
    "print(f\"LoRA Alpha: {peft_config.lora_alpha}\")\n",
    "print(f\"Target Modules: {peft_config.target_modules}\")\n",
    "print(f\"Trainable Parameters: {trainable_params:,}\")\n",
    "print(f\"Final Evaluation Accuracy: {eval_metrics['eval_accuracy']:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34",
   "metadata": {
    "id": "OWRHPPRL0GZO"
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import matplotlib.pyplot as plt\n",
    "def extract_metrics_from_logs(output_dir):\n",
    "    log_file = os.path.join(output_dir, \"trainer_state.json\")\n",
    "    if not os.path.exists(log_file):\n",
    "        print(f\"Log file not found at {log_file}\")\n",
    "        return None\n",
    "\n",
    "    with open(log_file, 'r') as f:\n",
    "        logs = json.load(f)\n",
    "\n",
    "    metrics_dict = {\n",
    "        'train_loss': [],\n",
    "        'eval_loss': [],\n",
    "        'eval_accuracy': [],\n",
    "        'steps': []\n",
    "    }\n",
    "\n",
    "    for log in logs.get('log_history', []):\n",
    "        if 'loss' in log and 'step' in log and 'eval_loss' not in log:\n",
    "            metrics_dict['train_loss'].append(log['loss'])\n",
    "            metrics_dict['steps'].append(log['step'])\n",
    "\n",
    "        if 'eval_loss' in log and 'eval_accuracy' in log:\n",
    "            metrics_dict['eval_loss'].append(log['eval_loss'])\n",
    "            metrics_dict['eval_accuracy'].append(log['eval_accuracy'])\n",
    "\n",
    "    return metrics_dict\n",
    "\n",
    "# 1. Plot training and evaluation metrics over time\n",
    "def plot_training_metrics(metrics_dict):\n",
    "    plt.figure(figsize=(12, 8))\n",
    "\n",
    "    # Plot training loss\n",
    "    plt.subplot(2, 1, 1)\n",
    "    plt.plot(metrics_dict['steps'][:len(metrics_dict['train_loss'])],\n",
    "             metrics_dict['train_loss'], 'b-', label='Training Loss')\n",
    "\n",
    "    # Create positions for eval metrics\n",
    "    eval_steps = np.linspace(0, max(metrics_dict['steps']), len(metrics_dict['eval_loss']))\n",
    "    plt.plot(eval_steps, metrics_dict['eval_loss'], 'r-', label='Evaluation Loss')\n",
    "\n",
    "    plt.title('Loss vs Training Steps')\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    # Plot evaluation accuracy\n",
    "    plt.subplot(2, 1, 2)\n",
    "    plt.plot(eval_steps, metrics_dict['eval_accuracy'], 'g-', label='Evaluation Accuracy')\n",
    "    plt.title('Accuracy vs Training Steps')\n",
    "    plt.xlabel('Training Steps')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.ylim(0.8, 1.0)  # Assuming accuracy is between 0.8 and 1.0, adjust as needed\n",
    "    plt.legend()\n",
    "    plt.grid(True, linestyle='--', alpha=0.7)\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('training_metrics.png', dpi=300)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 711
    },
    "id": "J0n668xz0Map",
    "outputId": "11d77d7a-2e55-419e-c75e-8a82ea39b30d"
   },
   "outputs": [],
   "source": [
    "metrics = extract_metrics_from_logs(\"roberta-lora-agnews-results/checkpoint-800/\")\n",
    "plot_training_metrics(metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36",
   "metadata": {
    "id": "jGW71Lhb1Mhj"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
